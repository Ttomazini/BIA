import streamlit as st
import openai
import os  # ğŸ‘ˆ novo import necessÃ¡rio
from PIL import Image
import base64
from io import BytesIO

# âœ… ConfiguraÃ§Ã£o inicial da pÃ¡gina (tem que ser o primeiro comando!)
st.set_page_config(page_title="âœ¨ Bia âœ¨")

# âœ… FunÃ§Ã£o para converter imagem local em base64
def get_image_base64(img_path):
    img = Image.open(img_path)
    buffered = BytesIO()
    img.save(buffered, format="PNG")
    img_base64 = base64.b64encode(buffered.getvalue()).decode()
    return img_base64

# âœ… Carrega nova imagem da logo (aviÃ£o)
img_base64 = get_image_base64("aviao.png")
st.markdown(
    f"""
    <div style='text-align: center;'>
        <img src='data:image/png;base64,{img_base64}' width='120' style='border-radius: 20%; box-shadow: 0px 4px 12px rgba(0,0,0,0.1); margin-bottom: 10px;' />
        <h2>âœ¨ Bia âœ¨</h2>
        <p style='font-size: 16px;'>Ei, eu sou a BIA (Bold InteligÃªncia Artificial), sua assistente da Bold!<br>
        TÃ´ aqui para DESCOMPLICAR seu dia: Atividades mais rÃ¡pidas, Conversas eficientes e tirar dÃºvidas!</p>
    </div>
    """,
    unsafe_allow_html=True
)

# âœ… ConfiguraÃ§Ã£o da API Key via variÃ¡vel de ambiente (Render)
openai.api_key = os.environ["OPENAI_API_KEY"]

# ID do assistente criado na plataforma OpenAI
assistant_id = "asst_HgFhlVBy2xLofnuBdDBMVzli"

# Inicializar a conversa (thread)
if "thread_id" not in st.session_state:
    thread = openai.beta.threads.create()
    st.session_state.thread_id = thread.id

# Exibir histÃ³rico de mensagens
if "messages" not in st.session_state:
    st.session_state.messages = []

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# Input para pergunta
if prompt := st.chat_input("Digite sua pergunta aqui"):

    # Exibir pergunta do usuÃ¡rio
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # Enviar pergunta para o Assistente
    openai.beta.threads.messages.create(
        thread_id=st.session_state.thread_id,
        role="user",
        content=prompt
    )

    run = openai.beta.threads.runs.create(
        thread_id=st.session_state.thread_id,
        assistant_id=assistant_id
    )

    # Aguarda a resposta
    with st.spinner("BIA estÃ¡ respondendo..."):
        while True:
            run_status = openai.beta.threads.runs.retrieve(
                thread_id=st.session_state.thread_id,
                run_id=run.id
            )
            if run_status.status == "completed":
                break

    # Recuperar resposta
    messages = openai.beta.threads.messages.list(thread_id=st.session_state.thread_id)
    resposta = messages.data[0].content[0].text.value

    # Exibir resposta
    st.session_state.messages.append({"role": "assistant", "content": resposta})
    with st.chat_message("assistant"):
        st.markdown(resposta)
